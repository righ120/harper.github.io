---
title : fri_20180928_3
layout : post
author : Heesoo Park
tags : [Text-to-image_generation]
---

<h3>AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks (CVPR 2017) </h3>


<p>

<b>Tao Xu<sup>1</sup>, Pengchuan Zhang<sup>2</sup>, Qiuyuan Huang<sup>2</sup>,Han Zhang<sup>3</sup>, Zhe Gan<sup>4</sup>, Xiaolei Huang<sup>1</sup>, Xiaodong He<sup>2</sup></b><br/>
<sup>1</sup>Lehigh University <sup>2</sup>Microsoft Research <sup>3</sup>Rutgers University <sup>4</sup>Duke University<br/>
<em>{tax313, xih206}@lehigh.edu, {penzhan, qihua, xiaohe}@microsoft.com</em><br/>
<em>han.zhang@cs.rutgers.edu, zhe.gan@duke.edu</em><br/>


</p>

<hr />
<p>
text to image task에서 attention을 접목한 GAN을 제안한다. image를 세분화하고 attention이 이미질ㄹ 생성할 때 관련 있는 단어에 집중함으로써 성능을 높일 수 있게 한다. 또한 generator를 학습시키는 과정에서 세부 이미지와 text가 얼마나 유사한지 계산하는 모델을 제안한다.<br/>

</p>