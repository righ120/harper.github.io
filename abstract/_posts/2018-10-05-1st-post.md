---
title : fri_20181005_1
layout : post
author : Heesoo Park
tags : [Word-Embeddings]
---

<h3>Dynamic Word Embeddings (ICML 2017)  </h3>


<p>

<b>Robert Bamler<sup>1</sup>  Stephan Mandt<sup>1</sup></b><br/>
<sup>1</sup>Disney Research, 4720 Forbes Avenue, Pittsburgh, PA 15213, USA.<br/>
<em>Robert.Bamler@disneyresearch.com  Stephan.Mandt@disneyresearch.com</em>



</p>

<hr />
<p>
이 모델은 단어와 문맥을 embedding 공간안에서 잠재 trajectory로 표현한다. 각각의 시점에서 단어는 확률적 word2vec을 통해 학습되고, 각각의 시점은 latent diffusion process로 연결되어 있다. 이 때 2가지 확장 가능한 VI 알고리즘을 통해 각 시점의 단어를 동시에 학습할 수 있게 한다.
</p>