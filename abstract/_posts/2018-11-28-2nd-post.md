---
title : wed_20181128_2
layout : post
author : Heesoo Park
tags : [optimizer]
---

<h3>ON THE INSUFFICIENCY OF EXISTING MOMENTUM
SCHEMES FOR STOCHASTIC OPTIMIZATION (ICLR 2018)</h3>


<p>
<b>Rahul Kidambi<sup>1</sup>, Praneeth Netrapalli<sup>2</sup>, Prateek Jain<sup>2</sup> and Sham M. Kakade<sup>1</sup></b><br/>
1 University of Washington Seattle 2 Microsoft Research India<br/>
<em>rkidambi@uw.edu, {praneeth, prajain}@microsoft.com,</em><br/>
<em>sham@cs.washington.edu</em>








</p>

<hr />
<p>
momentum 기반의 "fast gradient" method는 오직 deterministic 한 case 에서만 적용되고 stochastic한 case에선 SGD의 성능을 앞지를 수 없다. 이 논문에선, 일반적인 상황에서 이 방법이 실패할 수 있음을 보이고, 이전의 HB와 NAG가 얻은 gain이 mini-batch의 부산물임을 보인다. 또한 NAG 의 variant 기반의 방법으로 대안을 제시한다.
</p>
