---
title : mon_20181203_1
layout : post
author : Heesoo Park
tags : [Multi-Task_learning]
---

<h3>Calibrated Multi-Task Learning (KDD 2018)</h3>


<p>

<b>Feiping Nie</b><br/>
School of Computer Science<br/>
Center for OPTIMAL<br/>
Northwestern Polytechnical<br/>
University<br/>
Xi’an, China<Br/>
<em>feipingnie@gmail.com</em><br/><Br/>
<b>Zhanxuan Hu</b><br/>
School of Computer Science<br/>
Center for OPTIMAL<br/>
Northwestern Polytechnical<br/>
University<br/>
Xi’an, China<br/>
<em>huzhanxuan@mail.nwpu.edu.cn</em><br/><Br/>
<b>Xuelong Li</b><Br/>
OPTIMAL, Xian Institute of<br/>
Optics and Precision Mechanics<br/>
Chinese Academy of Sciences<br/>
Xi’an, China<br/>
<em>xuelong li@opt.ac.cn</em>








</p>

<hr />
<p>
Multi-Task learning에서 non-convex low rank regularizer를 통해 shared info를 전달한다. 또한 loss를 least squre loss에서 square-root loss, 이 두 개의 조합을 efficiently optimize 하는 re-weighted method를 제안한다. 이론적으로 이 방법의 convergence와 derived solution이 원래 문제의 stationary point라는 것을 증명한다.
</p>
